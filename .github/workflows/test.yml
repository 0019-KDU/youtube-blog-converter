name: Test Suite

on:
  push:
    branches: [main, development]
  pull_request:
    branches: [main, development]

env:
  # Test Environment Variables
  FLASK_SECRET_KEY: 'test-secret-key-for-testing-super-secret-12345'
  JWT_SECRET_KEY: 'test-jwt-secret-key-super-secret-12345'
  OPENAI_API_KEY: 'test-openai-key'
  SUPADATA_API_KEY: 'test-supadata-key'
  MONGODB_URI: 'mongodb://localhost:27017/test_db'
  MONGODB_DB_NAME: 'test_youtube_blog_db'
  FLASK_ENV: 'testing'
  TESTING: 'true'
  CI: 'true'

jobs:
  # Unit Tests - Run on every push
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10.0, 3.11]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-mock pytest-timeout
          
      - name: Run unit tests
        run: |
          pytest tests/unit/ \
            --cov=app \
            --cov=auth \
            --cov=src \
            --cov-report=xml:coverage-unit.xml \
            --cov-report=html:htmlcov-unit \
            --cov-report=term-missing \
            -v \
            -m "not slow" \
            --tb=short \
            --timeout=300
            
      - name: Upload unit test coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage-unit.xml
          flags: unit-tests
          name: codecov-unit
          fail_ci_if_error: false
          
      - name: Store unit test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-results-${{ matrix.python-version }}
          path: |
            coverage-unit.xml
            htmlcov-unit/
            pytest.xml

  # Integration Tests - Run on pull requests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [unit-tests]
    
    services:
      mongodb:
        image: mongo:5.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd mongo
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
          
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-mock pytest-timeout
          
      - name: Wait for MongoDB
        run: |
          timeout 30 bash -c 'until mongo --eval "db.adminCommand({ismaster: 1})" > /dev/null 2>&1; do sleep 1; done'
          
      - name: Run integration tests
        run: |
          pytest tests/integration/ \
            --cov=app \
            --cov=auth \
            --cov=src \
            --cov-report=xml:coverage-integration.xml \
            --cov-report=html:htmlcov-integration \
            --cov-report=term-missing \
            -v \
            -m "integration" \
            --tb=short \
            --timeout=600 \
            --run-integration
            
      - name: Upload integration test coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage-integration.xml
          flags: integration-tests
          name: codecov-integration
          fail_ci_if_error: false
          
      - name: Store integration test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: |
            coverage-integration.xml
            htmlcov-integration/
            pytest.xml

  # E2E Tests - Run only on main branch
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    needs: [unit-tests, integration-tests]
    
    services:
      mongodb:
        image: mongo:5.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd mongo
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
          
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-mock pytest-timeout selenium webdriver-manager
          
      - name: Setup Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@latest
        
      - name: Install ChromeDriver
        run: |
          pip install webdriver-manager
          
      - name: Wait for MongoDB
        run: |
          timeout 30 bash -c 'until mongo --eval "db.adminCommand({ismaster: 1})" > /dev/null 2>&1; do sleep 1; done'
          
      - name: Start application in background
        run: |
          python run.py &
          APP_PID=$!
          echo "APP_PID=$APP_PID" >> $GITHUB_ENV
          
          # Wait for app to start
          timeout 30 bash -c 'until curl -f http://localhost:5000/health > /dev/null 2>&1; do sleep 1; done' || true
          sleep 5
          
      - name: Run E2E tests
        run: |
          pytest tests/e2e/ \
            -v \
            -m "e2e" \
            --tb=short \
            --timeout=900 \
            --run-e2e
            
      - name: Stop application
        if: always()
        run: |
          if [ ! -z "$APP_PID" ]; then
            kill $APP_PID || true
          fi
          
      - name: Store E2E test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-results
          path: |
            pytest.xml
            screenshots/

  # Test Summary Job
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests]
    if: always()
    
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v3
        
      - name: Create test summary
        run: |
          echo "# Test Results Summary" > test-summary.md
          echo "" >> test-summary.md
          
          echo "## Unit Tests" >> test-summary.md
          if [ "${{ needs.unit-tests.result }}" = "success" ]; then
            echo "✅ **PASSED** - All unit tests passed" >> test-summary.md
          else
            echo "❌ **FAILED** - Unit tests failed" >> test-summary.md
          fi
          echo "" >> test-summary.md
          
          echo "## Integration Tests" >> test-summary.md
          if [ "${{ needs.integration-tests.result }}" = "success" ]; then
            echo "✅ **PASSED** - All integration tests passed" >> test-summary.md
          elif [ "${{ needs.integration-tests.result }}" = "skipped" ]; then
            echo "⏭️ **SKIPPED** - Integration tests skipped (not a PR)" >> test-summary.md
          else
            echo "❌ **FAILED** - Integration tests failed" >> test-summary.md
          fi
          echo "" >> test-summary.md
          
          echo "## E2E Tests" >> test-summary.md
          if [ "${{ needs.e2e-tests.result }}" = "success" ]; then
            echo "✅ **PASSED** - All E2E tests passed" >> test-summary.md
          elif [ "${{ needs.e2e-tests.result }}" = "skipped" ]; then
            echo "⏭️ **SKIPPED** - E2E tests skipped (not main branch)" >> test-summary.md
          else
            echo "❌ **FAILED** - E2E tests failed" >> test-summary.md
          fi
          
          cat test-summary.md
          
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const testSummary = fs.readFileSync('test-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: testSummary
            });

  # Fail fast if unit tests fail
  fail-fast-check:
    name: Fail Fast Check
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: failure()
    
    steps:
      - name: Fail pipeline if unit tests fail
        run: |
          echo "❌ Unit tests failed - stopping pipeline"
          exit 1